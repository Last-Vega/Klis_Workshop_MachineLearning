{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分類するクラス\n",
    "classes = ['Field', 'Undiscovered', 'Bug', 'Amorphous', 'Dragon', 'Fairy', 'Mineral', \n",
    "           'Flying', 'Grass', 'Human-Like', 'Monster', 'Water']\n",
    "\n",
    "nb_classes = len(classes)\n",
    "\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# トレーニング用とバリデーション用の画像格納先\n",
    "train_data_dir = 'AllDataSet/train'\n",
    "validation_data_dir = 'AllDataSet/validation'\n",
    "\n",
    "\n",
    "nb_train_samples = 5225\n",
    "nb_validation_samples = 4715\n",
    "\n",
    "batch_size = 64\n",
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_model_maker():\n",
    "    \"\"\" VGG16のモデルをFC層以外使用。FC層のみ作成して結合して用意する \"\"\"\n",
    "\n",
    "    # VGG16のロード。FC層は不要なので include_top=False\n",
    "    input_tensor = Input(shape=(img_width, img_height, 3))\n",
    "    vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "\n",
    "    # FC層の作成\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=vgg16.output_shape[1:]))\n",
    "    top_model.add(Dense(256, activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "    # VGG16とFC層を結合してモデルを作成\n",
    "    model = Model(inputs=vgg16.input, outputs=top_model(vgg16.output))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator():\n",
    "    \"\"\" ディレクトリ内の画像を読み込んでトレーニングデータとバリデーションデータの作成 \"\"\"\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1.0 / 255,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        color_mode='rgb',\n",
    "        classes=classes,\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        color_mode='rgb',\n",
    "        classes=classes,\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "\n",
    "    return (train_generator, validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = 'results'\n",
    "if not os.path.exists(result_dir):\n",
    "    os.mkdir(result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15246 images belonging to 12 classes.\n",
      "Found 4715 images belonging to 12 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/WatanabeShingo/anaconda3/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    }
   ],
   "source": [
    "# モデル作成\n",
    "vgg_model = vgg_model_maker()\n",
    "\n",
    "# 最後のconv層の直前までの層をfreeze\n",
    "for layer in vgg_model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 多クラス分類を指定\n",
    "vgg_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=1e-3, momentum=0.9),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 画像のジェネレータ生成\n",
    "train_generator, validation_generator = image_generator()\n",
    "\n",
    "# Fine-tuning\n",
    "\n",
    "history = vgg_model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=int(nb_train_samples/batch_size),\n",
    "    epochs=nb_epoch,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=int(nb_validation_samples/batch_size)\n",
    ")\n",
    "\n",
    "vgg_model.save_weights(os.path.join(result_dir, 'finetuning-4.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss     = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss,     marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss     = history.history['accuracy']\n",
    "val_loss = history.history['val_accuracy']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss,     marker='.', label='accuracy')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_accuracy')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
